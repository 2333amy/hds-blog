{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2333amy/hds-blog/blob/main/Week-07-Exercise-PCA-copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GNrOr-WiKQW"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1DXUVHxd4t15mfuqMgMCLnsP4jWVI5EWz)\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "Â© 2022 Copyright The University of New South Wales - CRICOS 00098G\n",
        "\n",
        "**Author**: Sebastiano Barbieri\n",
        "\n",
        "**Contributors/Co-authors**: Oscar Perez-Concha, Marta Fredes-Torres and Zhisheng (Sandy) Sa.\n",
        "\n",
        "# Week 7 - Exercise 1: PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN4p9w5eiKQY"
      },
      "source": [
        "# 1. Introduction\n",
        "\n",
        "In order to understand this exercise, read the README.md file and the reading material for this week first. \n",
        "\n",
        "## 1.1. Aims:\n",
        "1. Perform PCA using Scikit-Learn and singular value decomposition\n",
        "2. Select an appropriate number of principal components by computing the proportion of variance explained\n",
        "3. Understand what biplots represent\n",
        " \n",
        "## 1.2. Jupyter Notebook Intructions\n",
        "1. Read the content of each cell.\n",
        "2. Where necessary, follow the instructions that are written in each cell.\n",
        "3. Run/Execute all the cells that contain Python code sequentially (one at a time), using the \"Run\" button.\n",
        "4. For those cells in which you are asked to write some code, please write the Python code first and then execute/run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "skbhUSeQiKQa",
        "outputId": "4d804b25-cfa7-4368-857c-959785d1de83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing:  {'lime', 'grid', 'shap'}\n"
          ]
        }
      ],
      "source": [
        "# check required libraries are installed if not calling system to install\n",
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "required = {'numpy', 'pandas', 'plotnine', 'matplotlib', 'seaborn', \n",
        "            'grid', 'lime', 'shap', 'scikit-learn', 'graphviz'}\n",
        "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
        "missing = required - installed\n",
        "\n",
        "if missing:\n",
        "    print('Installing: ', missing)\n",
        "    python = sys.executable\n",
        "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
        "# delete unwanted variables\n",
        "del required \n",
        "del installed \n",
        "del missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8p62DC4iKQb"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "# We do not need to run this cell if you are not running this notebook in Google Colab\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive # import drive from Gogle colab\n",
        "    root = '/content/drive'     # default location for the drive\n",
        "    # print(root)                 # print content of ROOT (Optional)\n",
        "    drive.mount(root)\n",
        "else:\n",
        "    print('Not running on CoLab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRNGzaEjiKQc"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    # EDIT THE PROJECT PATH IF DIFFERENT WITH YOUR ONE\n",
        "    project_path = Path(root) / 'MyDrive' / 'HDAT9500' / 'week07'\n",
        "\n",
        "    # OPTIONAL - set working directory according to your google drive project path\n",
        "    # import os\n",
        "    # Change directory to the location defined in project_path\n",
        "    # os.chdir(project_path)\n",
        "else:\n",
        "    project_path = Path()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbpJocChpcTR"
      },
      "source": [
        "# 2. Docstring: \n",
        "\n",
        "Create a docstring with the variables and constants that you will use in this exercise (data dictionary) and the purpose of your program. It is expected that you choose informative variable names and document your program (both docstrings and comments)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2zvhr_epcTS"
      },
      "source": [
        "<b> Write the answer here:</b>\n",
        "\n",
        "#####################################################################################################################\n",
        "\n",
        "(double-click here)\n",
        "\n",
        "\n",
        "#####################################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipgKV56TiKQd"
      },
      "source": [
        "# 3. Dataset: Breast Cancer Wisconsin (Diagnostic) Data Set\n",
        "\n",
        "## 3.1. Data Set Information:\n",
        "\n",
        "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. \n",
        "This database is also available through the UW CS ftp server use following code: `ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/` and the UCI Machine Learning Repository for [the data dictionary and more information](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)\n",
        "\n",
        "## 3.2. Attribute Information:\n",
        "\n",
        "1. ID number\n",
        "2. Diagnosis (M = malignant, B = benign)\n",
        "3. to 32. Ten real-valued features are computed for each cell nucleus:\n",
        "\n",
        "\n",
        "    a. radius (mean of distances from center to points on the perimeter)\n",
        "\n",
        "    b. texture (standard deviation of gray-scale values)\n",
        "\n",
        "    c. perimeter\n",
        "\n",
        "    d. area\n",
        "\n",
        "    e. smoothness (local variation in radius lengths)\n",
        "\n",
        "    f. compactness (perimeter^2/area - 1.0)\n",
        "\n",
        "    g. concavity (severity of concave portions of the contour)\n",
        "\n",
        "    h. concave points (number of concave portions of the contour)\n",
        "\n",
        "    i. symmetry\n",
        "    \n",
        "    j. fractal dimension (\"coastline approximation\" - 1)\n",
        "\n",
        "The mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n",
        "\n",
        "All feature values are recoded with four significant digits.\n",
        "\n",
        "Missing attribute values: none\n",
        "\n",
        "Class distribution: 357 benign, 212 malignant\n",
        "\n",
        "[Further information](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GN2n0X7iKQe"
      },
      "source": [
        "## 3.3. Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGnxNC1kiKQf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TKQUWgZiKQg"
      },
      "source": [
        "Import the dataset and print it. Have a look at the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_SQ82nOiKQh"
      },
      "outputs": [],
      "source": [
        "data_path = Path(project_path) / 'data' / 'breast-cancer-wisconsin-data' / 'data.csv'\n",
        "bcw = pd.read_csv(data_path, sep=',')\n",
        "print(bcw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNQiksO-iKQh"
      },
      "outputs": [],
      "source": [
        "bcw.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vquHJKrjiKQi"
      },
      "source": [
        "## 4. Principal Component Analysis\n",
        "\n",
        "## 4.1. PCA Using Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxwcgwTgiKQi"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PgPfi11iKQi"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G23CqVW9iKQi"
      },
      "source": [
        "Select the first <font color=green><b>10</b></font> numerical features in the dataset; these will be our feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2EFCidYiKQj"
      },
      "outputs": [],
      "source": [
        "print(bcw.columns)\n",
        "X = bcw[bcw.columns[2:12]]\n",
        "X.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfqKwvshiKQj"
      },
      "source": [
        "Scale data to have zero mean and unit variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuGAw1r6iKQk"
      },
      "outputs": [],
      "source": [
        "X_scaled = preprocessing.scale(X)\n",
        "print(X_scaled.mean(axis=0))\n",
        "print(X_scaled.std(axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmSgBAzyiKQk"
      },
      "source": [
        "PCA, keep first two principal components\n",
        "\n",
        "[Read more on PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40bMqfR6iKQk"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components = 2)\n",
        "X2D = pca.fit_transform(X_scaled)\n",
        "print(X2D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIXQA6ETiKQk"
      },
      "source": [
        "Look at the loadings of the first two principal components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76sKhNxBiKQl"
      },
      "outputs": [],
      "source": [
        "print(pca.components_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01JkJeQaiKQl"
      },
      "source": [
        "## 4.2. Biplot "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYksXuGMiKQl"
      },
      "source": [
        "For more information regarding this function:\n",
        "\n",
        "1. [Biplot function](https://sukhbinder.wordpress.com/2015/08/05/biplot-with-python/) and\n",
        "[PCA](https://towardsdatascience.com/pca-clearly-explained-how-when-why-to-use-it-and-feature-importance-a-guide-in-python-7c274582c37e)\n",
        "\n",
        "2. [What is a biplot?](https://en.wikipedia.org/wiki/Biplot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsmFcsrmiKQm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Class labels\n",
        "y = bcw.loc[:, 'diagnosis']\n",
        "\n",
        "# Define biplot\n",
        "def biplot(score, coeff, labels=None):\n",
        "    xs = score[:,0]\n",
        "    ys = score[:,1]\n",
        "    n = coeff.shape[0]\n",
        "    scalex = 1.0/(xs.max() - xs.min())\n",
        "    scaley = 1.0/(ys.max() - ys.min())\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(8,8))\n",
        "    for g in np.unique(y):\n",
        "        ix = np.where(y == g)\n",
        "        ax.scatter(xs[ix] * scalex, ys[ix] * scaley, label = g)\n",
        "    for i in range(n):\n",
        "        plt.arrow(0, 0, coeff[i,0], coeff[i,1], color = 'r', alpha = 0.5)\n",
        "        if labels is None:\n",
        "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
        "        else:\n",
        "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, labels[i], color = 'g', ha = 'center', va = 'center')\n",
        "    plt.xlabel(\"PC{}\".format(1))\n",
        "    plt.ylabel(\"PC{}\".format(2))\n",
        "    plt.legend(loc='best')\n",
        "    plt.grid()\n",
        "\n",
        "# Call the function. Use only the 2 principal components.\n",
        "biplot(X2D, pca.components_.T, X.columns)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw6RzRGxiKQm"
      },
      "source": [
        "All the loadings of the first principal component are positive while for the second principal component some loadings are positive and some are negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jgljGariKQm"
      },
      "source": [
        "## 4.3. Proportion of Variance Explained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K92wasFqiKQn"
      },
      "source": [
        "Determine the proportion of variance explained by each of the first two principal components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiARjO1QiKQn"
      },
      "outputs": [],
      "source": [
        "pve = pca.explained_variance_ratio_\n",
        "print(pve)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEFsKzLZiKQo"
      },
      "source": [
        "The first dimension explains 54.8% of the variance, while the second explains 25.2%.\n",
        "How much variance do both principal components explain?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT5qOOfRiKQo"
      },
      "outputs": [],
      "source": [
        "print(sum(pve))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzP8ZLsZiKQo"
      },
      "source": [
        "How many principal components do we need to explain 95% of the data variance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dPwBKcTiKQp"
      },
      "outputs": [],
      "source": [
        "# Compute PCA without reducing dimensionality\n",
        "pca = PCA()\n",
        "pca.fit(X_scaled)\n",
        "\n",
        "# Plot the cumulative sum of explained variance\n",
        "cumulative_sum = np.cumsum(pca.explained_variance_ratio_)\n",
        "plt.plot(cumulative_sum)\n",
        "plt.xlabel('Dimension')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Compute the minimum number of dimensions d that explain 95% of the data variance\n",
        "d = np.argmax(cumulative_sum >= 0.95)+1\n",
        "print(\"Minimum number of dimensions that explain 95% of the data variance:\")\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUx3eEc8iKQp"
      },
      "source": [
        "We could now re-run pca with n_components=d. However, you can also set n_components to be a float between 0.0 and 1.0 indicating the proportion of variance you wish to preserve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yClgEtFwiKQp"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=0.95)\n",
        "XDD = pca.fit_transform(X_scaled)\n",
        "print(XDD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBJ7B9hyiKQp"
      },
      "source": [
        "Congratulations, you now know how to reduce the dimensionality of any dataset down to any number of dimensions, while preserving as much variance as possible!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYOVWp4ViKQq"
      },
      "source": [
        "Â© 2022 Copyright The University of New South Wales - CRICOS 00098G"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Chapter07-Exercise-PCA.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}